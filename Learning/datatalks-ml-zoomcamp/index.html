<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Datatalks ML zoomcamp - BERA LOGS</title><link rel="manifest" href="/manifest.json"><meta name="theme-color" content="#f7f7f7"><meta name="application-name" content="Iphigenie Bera"><meta name="msapplication-TileImage" content="https://avatars.githubusercontent.com/u/84729199?s=400&amp;u=7d8faf6aeb2c7790f9770f718609c65eb5278114&amp;v=4"><meta name="msapplication-TileColor" content="#f7f7f7"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Iphigenie Bera"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="IntroductionThis machine learning zoomcamp is an online-based machine learning course by Datatalks.Club. it is a learn-by-doing class teaching bread-and-butter skills and techniques in machine learnin"><meta property="og:type" content="blog"><meta property="og:title" content="Datatalks ML zoomcamp"><meta property="og:url" content="https://iphixli.github.io/Learning/datatalks-ml-zoomcamp/"><meta property="og:site_name" content="BERA LOGS"><meta property="og:description" content="IntroductionThis machine learning zoomcamp is an online-based machine learning course by Datatalks.Club. it is a learn-by-doing class teaching bread-and-butter skills and techniques in machine learnin"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://iphixli.github.io/gallery/datatalks_ML.jpg"><meta property="article:published_time" content="2022-09-06T02:35:48.000Z"><meta property="article:author" content="Bera Iphigenie"><meta property="article:tag" content="Machine learning"><meta property="article:tag" content="Datatalks"><meta property="article:tag" content="study-notes"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://iphixli.github.io/gallery/datatalks_ML.jpg"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://iphixli.github.io/Learning/datatalks-ml-zoomcamp/"},"headline":"Datatalks ML zoomcamp","image":["https://iphixli.github.io/gallery/datatalks_ML.jpg"],"datePublished":"2022-09-06T02:35:48.000Z","author":{"@type":"Person","name":"Bera Iphigenie"},"publisher":{"@type":"Organization","name":"BERA LOGS","logo":{"@type":"ImageObject","url":"https://iphixli.github.io/Learning/datatalks-ml-zoomcamp/"}},"description":"IntroductionThis machine learning zoomcamp is an online-based machine learning course by Datatalks.Club. it is a learn-by-doing class teaching bread-and-butter skills and techniques in machine learnin"}</script><link rel="canonical" href="https://iphixli.github.io/Learning/datatalks-ml-zoomcamp/"><link rel="icon" href="https://avatars.githubusercontent.com/u/84729199?s=400&amp;u=7d8faf6aeb2c7790f9770f718609c65eb5278114&amp;v=4"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-dark.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const $tabMenu = document.querySelector(`a[href="${location.hash}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(location.hash);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/">BERA LOGS</a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/about">About</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/Bera_resumesummer2022.pdf">Resume</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/IphixLi"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="Catalogue" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><div class="card-image"><span class="image is-7by3"><img class="fill" src="/gallery/datatalks_ML.jpg" alt="Datatalks ML zoomcamp"></span></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-09-06T02:35:48.000Z" title="9/5/2022, 9:35:48 PM">2022-09-05</time></span><span class="level-item"><a class="link-muted" href="/categories/Learning/">Learning</a></span><span class="level-item">19 minutes read (About 2919 words)</span></div></div><h1 class="title is-3 is-size-4-mobile">Datatalks ML zoomcamp</h1><div class="content"><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>This machine learning zoomcamp is an online-based machine learning course by Datatalks.Club. it is a learn-by-doing class teaching bread-and-butter skills and techniques in machine learning with projects.</p>
<span id="more"></span>
<p>The course primarily runs synchronously in cohorts for around 4 months which successful completion of 2 of 3 projects guaranting a certificate. The lecture slides, video and resources are freely available in <a target="_blank" rel="noopener" href="https://github.com/alexeygrigorev/mlbookcamp-code/tree/master/course-zoomcamp">this course github</a>. I am taking fall cohort 2022 which officially started 5 September 2022.</p>
<p>in this post I will post course notes by weeks and links to my homeworks completions.</p>
<h2 id="Week-1-Introduction-to-Machine-Learning"><a href="#Week-1-Introduction-to-Machine-Learning" class="headerlink" title="Week 1 - Introduction to Machine Learning"></a>Week 1 - Introduction to Machine Learning</h2><p><strong>introduction to ML</strong></p>
<p>machine learning is the process in the process of extracting patterns from data. machine learning allow us to make models that can classify data given or predict for the future.</p>
<p>data can be separated into two types:</p>
<ul>
<li>features : information about the object such as attributes in dataset such as mileage, age, horsepower, location etc. these are the base data for making prediction</li>
<li>target: this is the attribute we are developing model to predict for or classify against. for example it can be price of sales prediction.</li>
</ul>
<p><strong>ML vs Rule-Based Systems</strong></p>
<p>Rule-Based systems involves manually setting rules and thresholds for prediction and classification however with ever changing data, these systems fails terribly or required a lot of resources and time to adjust to changes.</p>
<p>this is where Machine learning come to the save. Machine learning model is trained to find underlying patterns in given data and develop its own thresholds and rules with the help of probability and historical data points.</p>
<p>letâ€™s take an example with spam filter. </p>
<p>using a rule-based system we can define indicators in the email which can define email as a spam or not such as sender email and email-body contents however sneeky email-sender would quickly bypass this by simply avoiding these rules.</p>
<p>with machine learning we can use our training dataset and find out underlying patterns in emails which would suggest if email is spam or not without necessarily knowing them beforehand.</p>
<p><strong>types of Machine learning</strong></p>
<p>there are two types:</p>
<ul>
<li><p>Supervised machine learning: they rely on data for which a known target exists (often referred to as labels). these predict output based on training datasets with input-output pairs.</p>
</li>
<li><p>unsupervised machine learning&#x2F;reinforced learning:discover hidden patterns or data groupings without the need of having input-output pairs in training dataset. these fall outside scope of this class.</p>
</li>
</ul>
<p><strong>supervised machine learning</strong></p>
<p> As said, in supervised machine learning, features are associated with labels. model is trained to associate features with particular labels. this can be done by threshold cutoffs or discrete value association.</p>
<p>There is features and targets.</p>
<p>features matrix is rows as observations and columns as attributes
target matrix: usually a verctor with information we want to predict</p>
<p><strong>Types of Supervised ML problems</strong></p>
<ul>
<li>Regression: the output is a number (carâ€™s prize)</li>
<li>Classification: the output is a category (spam example).</li>
<li>Ranking: the output is the big scores associated with certain items. items are ranked according to their measuring attributes(recommender systems)</li>
</ul>
<p><strong>CRISP-DM</strong></p>
<p>The CRoss Industry Standard Process for Data Mining (CRISP-DM) is a methodology for organizing ML projects invented by IBM.</p>
<ul>
<li><em>Business understanding</em>:do we need ML for the project. are the benefits outweighting costs and uncertainty manageble?
Data understanding: Analyze available data sources, and decide if more data is required and transformations that would be needed.</li>
<li><em>Data preparation</em>: Clean data and remove noise applying pipelines, and the data should be converted to a tabular format, so we can put it into ML.</li>
<li><em>Modeling</em>: training data on different models and choose the best one. consider if you would need additional features, data or remove redundant features.</li>
<li><em>Evaluation</em>: Measure how well the model is performing and if it solves the business problem.</li>
<li><em>Deployment</em>: Roll out to production to all the users. The evaluation and deployment often happen together</li>
</ul>
<p><strong>Environment</strong>
The main programming language used for the course is Python. It is a simple, yet robust language when it comes to handling data. at the time of taking, I used Python 3.9. We used Anaconda python distribution because of benefits of having important data science library we would need; these includes:</p>
<ul>
<li><em>NumPy</em>: python library for scientific computing expecially with arrays.</li>
<li><em>Pandas</em>: python library for handling tabular data</li>
<li><em>Scikit-Learn</em>:python library for machine-learning models</li>
<li><em>Matplotlib and Seaborn</em>: python library for data visualization</li>
<li><em>Jupyter notebooks</em>: web application for sharing computing documents with input scripting and plain-text capabilities</li>
</ul>
<h2 id="Week-2-Regression"><a href="#Week-2-Regression" class="headerlink" title="Week 2 - Regression"></a>Week 2 - Regression</h2><p><strong>Introduction</strong></p>
<p>Regression is a supervised machine learning technique. it is used for investigating relation between independent variables and dependent variables. it predicts a dependent variable using a set of indepent variables.</p>
<p>in this week, we worked on a project for predicting car prices using regression. dataset used was from this <a target="_blank" rel="noopener" href="https://www.kaggle.com/datasets/CooperUnion/cardataset">kaggle competition</a>.</p>
<p><em>project plan:</em></p>
<ul>
<li><p><a href="#EDA">Prepare data and Exploratory data analysis (EDA)</a></p>
</li>
<li><p><a href="#validate">Validation Framework</a></p>
</li>
<li><p><a href="#regression">linear regression</a></p>
</li>
<li><p><a href="#rmse">Evaluating the model</a></p>
</li>
<li><p><a href="#featureEng">Feature engineering</a></p>
</li>
<li><p><a href="#Regularization">Regularization</a></p>
</li>
<li><p><a href="#model">Using the model</a></p>
</li>
</ul>
<p><strong>Prepare data and Exploratory data analysis (EDA)</strong> <a name="EDA"></a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#import necessary libraries for EDA</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure>
<p>read data and preview the first elements in the table</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df = pd.read_csv(<span class="string">&#x27;data.csv&#x27;</span>)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure>
<div style="overflow-x: scroll;">
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
    .dataframe tbody tr th {
        vertical-align: top;
    }

<pre><code>.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style></p>
<table  markdown="block" border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Make</th>
      <th>Model</th>
      <th>Year</th>
      <th>Engine Fuel Type</th>
      <th>Engine HP</th>
      <th>Engine Cylinders</th>
      <th>Transmission Type</th>
      <th>Driven_Wheels</th>
      <th>Number of Doors</th>
      <th>Market Category</th>
      <th>Vehicle Size</th>
      <th>Vehicle Style</th>
      <th>highway MPG</th>
      <th>city mpg</th>
      <th>Popularity</th>
      <th>MSRP</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>BMW</td>
      <td>1 Series M</td>
      <td>2011</td>
      <td>premium unleaded (required)</td>
      <td>335.0</td>
      <td>6.0</td>
      <td>MANUAL</td>
      <td>rear wheel drive</td>
      <td>2.0</td>
      <td>Factory Tuner,Luxury,High-Performance</td>
      <td>Compact</td>
      <td>Coupe</td>
      <td>26</td>
      <td>19</td>
      <td>3916</td>
      <td>46135</td>
    </tr>
    <tr>
      <th>1</th>
      <td>BMW</td>
      <td>1 Series</td>
      <td>2011</td>
      <td>premium unleaded (required)</td>
      <td>300.0</td>
      <td>6.0</td>
      <td>MANUAL</td>
      <td>rear wheel drive</td>
      <td>2.0</td>
      <td>Luxury,Performance</td>
      <td>Compact</td>
      <td>Convertible</td>
      <td>28</td>
      <td>19</td>
      <td>3916</td>
      <td>40650</td>
    </tr>
    <tr>
      <th>2</th>
      <td>BMW</td>
      <td>1 Series</td>
      <td>2011</td>
      <td>premium unleaded (required)</td>
      <td>300.0</td>
      <td>6.0</td>
      <td>MANUAL</td>
      <td>rear wheel drive</td>
      <td>2.0</td>
      <td>Luxury,High-Performance</td>
      <td>Compact</td>
      <td>Coupe</td>
      <td>28</td>
      <td>20</td>
      <td>3916</td>
      <td>36350</td>
    </tr>
    <tr>
      <th>3</th>
      <td>BMW</td>
      <td>1 Series</td>
      <td>2011</td>
      <td>premium unleaded (required)</td>
      <td>230.0</td>
      <td>6.0</td>
      <td>MANUAL</td>
      <td>rear wheel drive</td>
      <td>2.0</td>
      <td>Luxury,Performance</td>
      <td>Compact</td>
      <td>Coupe</td>
      <td>28</td>
      <td>18</td>
      <td>3916</td>
      <td>29450</td>
    </tr>
    <tr>
      <th>4</th>
      <td>BMW</td>
      <td>1 Series</td>
      <td>2011</td>
      <td>premium unleaded (required)</td>
      <td>230.0</td>
      <td>6.0</td>
      <td>MANUAL</td>
      <td>rear wheel drive</td>
      <td>2.0</td>
      <td>Luxury</td>
      <td>Compact</td>
      <td>Convertible</td>
      <td>28</td>
      <td>18</td>
      <td>3916</td>
      <td>34500</td>
    </tr>
  </tbody>
</table>
</div>



<p>Some table properties</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#get the destribution statistics for numerical columns/attributes</span></span><br><span class="line">df.describe()</span><br></pre></td></tr></table></figure>




<div style="overflow-x: scroll;">
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Year</th>
      <th>Engine HP</th>
      <th>Engine Cylinders</th>
      <th>Number of Doors</th>
      <th>highway MPG</th>
      <th>city mpg</th>
      <th>Popularity</th>
      <th>MSRP</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>11914.000000</td>
      <td>11845.00000</td>
      <td>11884.000000</td>
      <td>11908.000000</td>
      <td>11914.000000</td>
      <td>11914.000000</td>
      <td>11914.000000</td>
      <td>1.191400e+04</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>2010.384338</td>
      <td>249.38607</td>
      <td>5.628829</td>
      <td>3.436093</td>
      <td>26.637485</td>
      <td>19.733255</td>
      <td>1554.911197</td>
      <td>4.059474e+04</td>
    </tr>
    <tr>
      <th>std</th>
      <td>7.579740</td>
      <td>109.19187</td>
      <td>1.780559</td>
      <td>0.881315</td>
      <td>8.863001</td>
      <td>8.987798</td>
      <td>1441.855347</td>
      <td>6.010910e+04</td>
    </tr>
    <tr>
      <th>min</th>
      <td>1990.000000</td>
      <td>55.00000</td>
      <td>0.000000</td>
      <td>2.000000</td>
      <td>12.000000</td>
      <td>7.000000</td>
      <td>2.000000</td>
      <td>2.000000e+03</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>2007.000000</td>
      <td>170.00000</td>
      <td>4.000000</td>
      <td>2.000000</td>
      <td>22.000000</td>
      <td>16.000000</td>
      <td>549.000000</td>
      <td>2.100000e+04</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>2015.000000</td>
      <td>227.00000</td>
      <td>6.000000</td>
      <td>4.000000</td>
      <td>26.000000</td>
      <td>18.000000</td>
      <td>1385.000000</td>
      <td>2.999500e+04</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>2016.000000</td>
      <td>300.00000</td>
      <td>6.000000</td>
      <td>4.000000</td>
      <td>30.000000</td>
      <td>22.000000</td>
      <td>2009.000000</td>
      <td>4.223125e+04</td>
    </tr>
    <tr>
      <th>max</th>
      <td>2017.000000</td>
      <td>1001.00000</td>
      <td>16.000000</td>
      <td>4.000000</td>
      <td>354.000000</td>
      <td>137.000000</td>
      <td>5657.000000</td>
      <td>2.065902e+06</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#number of entries/data rows</span></span><br><span class="line">df.shape[<span class="number">0</span>]</span><br></pre></td></tr></table></figure>




<pre><code>11914
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#number of attributes/columns</span></span><br><span class="line">df.shape[<span class="number">1</span>]</span><br></pre></td></tr></table></figure>




<pre><code>16
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#formating non-numeral columns to remove spaces</span></span><br><span class="line">df.columns = df.columns.<span class="built_in">str</span>.lower().<span class="built_in">str</span>.replace(<span class="string">&#x27; &#x27;</span>, <span class="string">&#x27;_&#x27;</span>)</span><br><span class="line"></span><br><span class="line">string_columns = <span class="built_in">list</span>(df.dtypes[df.dtypes == <span class="string">&#x27;object&#x27;</span>].index)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> attr <span class="keyword">in</span> string_columns:</span><br><span class="line">    df[attr] = df[attr].<span class="built_in">str</span>.lower().<span class="built_in">str</span>.replace(<span class="string">&#x27; &#x27;</span>, <span class="string">&#x27;_&#x27;</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">7</span>, <span class="number">5</span>))</span><br><span class="line"></span><br><span class="line">sns.histplot(df.msrp, bins=<span class="number">40</span>, alpha=<span class="number">1</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Frequency&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Price&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Distribution of prices&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/gallery/output_9_0.png" alt="Distribution of prices"></p>
<p>distribution of prices, focusing on prices with lower frequencies</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">6</span>, <span class="number">4</span>))</span><br><span class="line"></span><br><span class="line">sns.histplot(df.msrp[df.msrp &lt; <span class="number">100000</span>], bins=<span class="number">40</span>, alpha=<span class="number">1</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Frequency&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Price&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Distribution of prices&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/gallery/output_11_0.png" alt="lower Distribution of prices"></p>
<p>check for columns with null attributes</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.isnull().<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure>




<pre><code>make                    0
model                   0
year                    0
engine_fuel_type        3
engine_hp              69
engine_cylinders       30
transmission_type       0
driven_wheels           0
number_of_doors         6
market_category      3742
vehicle_size            0
vehicle_style           0
highway_mpg             0
city_mpg                0
popularity              0
msrp                    0
dtype: int64
</code></pre>
<p>Long-tail distributions usually confuse the ML models, so the recommendation is to transform the target variable distribution to a normal one whenever possible. we use log transformation since our data have a long tail suggesting logarithmic distribution</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">log_price = np.log1p(df.msrp)</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">6</span>, <span class="number">4</span>))</span><br><span class="line"></span><br><span class="line">sns.histplot(log_price, bins=<span class="number">40</span>, alpha=<span class="number">1</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Frequency&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Log(Price + 1)&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Distribution of prices after log tranformation&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/gallery/output_15_0.png" alt="logarithmic distribution of prices"></p>
<p><strong>Validation Framework</strong> <a name="validate"></a></p>
<p>The dataset is split into three parts: training, validation, and test. For each partition, we obtain feature matrices (X) and y vectors of targets.
The size of partitions is calculated, records are shuffled to guarantee that values of the three partitions contain non-sequential records of the dataset.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#to allow reproducibility when the code is rerun the second time</span></span><br><span class="line">np.random.seed(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">n=<span class="built_in">len</span>(df) <span class="comment">#number of rows</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#performing the split according to ratios</span></span><br><span class="line">n_val = <span class="built_in">int</span>(<span class="number">0.2</span> * n)</span><br><span class="line">n_test = <span class="built_in">int</span>(<span class="number">0.2</span> * n)</span><br><span class="line">n_train = n - (n_val + n_test)</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">idx = np.arange(n) <span class="comment">#array of numbers from 0 to n</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#shuffle the number to ensure randomness</span></span><br><span class="line">np.random.shuffle(idx)</span><br><span class="line"></span><br><span class="line"><span class="comment">#shuffle table</span></span><br><span class="line">df_shuffled = df.iloc[idx]</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#partition</span></span><br><span class="line">df_train = df_shuffled.iloc[:n_train].copy()</span><br><span class="line">df_val = df_shuffled.iloc[n_train:n_train+n_val].copy()</span><br><span class="line">df_test = df_shuffled.iloc[n_train+n_val:].copy()</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">y_train_orig = df_train.msrp.values</span><br><span class="line">y_val_orig = df_val.msrp.values</span><br><span class="line">y_test_orig = df_test.msrp.values</span><br><span class="line"></span><br><span class="line"><span class="comment">#log transformation</span></span><br><span class="line">y_train = np.log1p(df_train.msrp.values)</span><br><span class="line">y_val = np.log1p(df_val.msrp.values)</span><br><span class="line">y_test = np.log1p(df_test.msrp.values)</span><br><span class="line"></span><br><span class="line"><span class="keyword">del</span> df_train[<span class="string">&#x27;msrp&#x27;</span>]</span><br><span class="line"><span class="keyword">del</span> df_val[<span class="string">&#x27;msrp&#x27;</span>]</span><br><span class="line"><span class="keyword">del</span> df_test[<span class="string">&#x27;msrp&#x27;</span>]</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>Linear Regression</strong> <a name="regression"></a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train_linear_regression</span>(<span class="params">X,y</span>):</span><br><span class="line">    ones=np.ones(X.shape[<span class="number">0</span>])</span><br><span class="line">    X=np.column_stack([ones,X])</span><br><span class="line">    XTX=X.T.dot(X)</span><br><span class="line">    XTX_inv=np.linalg.inv(XTX)</span><br><span class="line">    w=XTX_inv.dot(X.T).dot(y)</span><br><span class="line">    <span class="keyword">return</span> w[<span class="number">0</span>],w[<span class="number">1</span>:]</span><br></pre></td></tr></table></figure>

<p>######prediction</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">base = [<span class="string">&#x27;engine_hp&#x27;</span>, <span class="string">&#x27;engine_cylinders&#x27;</span>, <span class="string">&#x27;highway_mpg&#x27;</span>, <span class="string">&#x27;city_mpg&#x27;</span>, <span class="string">&#x27;popularity&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">prepare_X</span>(<span class="params">df</span>):</span><br><span class="line">    df_num = df[base]</span><br><span class="line">    df_num = df_num.fillna(<span class="number">0</span>)</span><br><span class="line">    X = df_num.values</span><br><span class="line">    <span class="keyword">return</span> X</span><br><span class="line"></span><br><span class="line">X_train = prepare_X(df_train)</span><br><span class="line">w_0, w = train_linear_regression(X_train, y_train)</span><br><span class="line"><span class="built_in">print</span>(w_0,w)</span><br></pre></td></tr></table></figure>

<pre><code>7.927257388070001 [ 9.70589522e-03 -1.59103494e-01  1.43792133e-02  1.49441072e-02
 -9.06908672e-06]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#prot for measuring descrepancy</span></span><br><span class="line">y_pred = w_0 + X_train.dot(w)</span><br><span class="line">plt.figure(figsize=(<span class="number">6</span>, <span class="number">4</span>))</span><br><span class="line">sns.histplot(y_train, label=<span class="string">&#x27;target&#x27;</span>, color=<span class="string">&#x27;blue&#x27;</span>, alpha=<span class="number">0.8</span>, bins=<span class="number">40</span>)</span><br><span class="line">sns.histplot(y_pred, label=<span class="string">&#x27;prediction&#x27;</span>, color=<span class="string">&#x27;yellow&#x27;</span>, alpha=<span class="number">0.8</span>, bins=<span class="number">40</span>)</span><br><span class="line"></span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.ylabel(<span class="string">&#x27;Frequency&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Log(Price + 1)&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Predictions vs actual distribution&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p><img src="/gallery/output_27_0.png" alt="Predictions vs actual distribution"></p>
<p><strong>RMSE Evaluation</strong> <a name="rmse"></a></p>
<p>uses root mean square error to measure efficiency of model. he RMSE represents the differences between predicted values and observed values. the lower the RSME the better the model.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">rmse</span>(<span class="params">y, y_pred</span>):</span><br><span class="line">    error = y_pred - y</span><br><span class="line">    mse = (error ** <span class="number">2</span>).mean()</span><br><span class="line">    <span class="keyword">return</span> np.sqrt(mse)</span><br><span class="line">rmse(y_train, y_pred)</span><br></pre></td></tr></table></figure>

<pre><code>0.7554192603920132
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#from validation set</span></span><br><span class="line">X_val = prepare_X(df_val)</span><br><span class="line">y_pred = w_0 + X_val.dot(w)</span><br><span class="line">rmse(y_val, y_pred)</span><br></pre></td></tr></table></figure>

<pre><code>0.7616530991301594
</code></pre>
<p><strong>feature engineering</strong> <a name="featureEng"></a></p>
<p>feature engineering is manipulating dataset such as addition, deletion, combination, mutation to improve machine learning model training, leading to better performance and greater accuracy.our goal is to have as smaller RSME as possible</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">prepare_X</span>(<span class="params">df</span>):</span><br><span class="line">    df = df.copy()</span><br><span class="line">    features = base.copy()</span><br><span class="line"></span><br><span class="line">    df[<span class="string">&#x27;age&#x27;</span>] = <span class="number">2017</span> - df.year</span><br><span class="line">    features.append(<span class="string">&#x27;age&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    df_num = df[features]</span><br><span class="line">    df_num = df_num.fillna(<span class="number">0</span>)</span><br><span class="line">    X = df_num.values</span><br><span class="line">    <span class="keyword">return</span> X</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">X_train = prepare_X(df_train)</span><br><span class="line">w_0, w = train_linear_regression(X_train, y_train)</span><br><span class="line"></span><br><span class="line">y_pred = w_0 + X_train.dot(w)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;train&#x27;</span>, rmse(y_train, y_pred))</span><br><span class="line"></span><br><span class="line">X_val = prepare_X(df_val)</span><br><span class="line">y_pred = w_0 + X_val.dot(w)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;validation&#x27;</span>, rmse(y_val, y_pred))</span><br></pre></td></tr></table></figure>

<pre><code>train 0.5175055465840046
validation 0.5172055461058324
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">&#x27;make&#x27;</span>].value_counts().head(<span class="number">5</span>)</span><br></pre></td></tr></table></figure>




<pre><code>chevrolet     1123
ford           881
volkswagen     809
toyota         746
dodge          626
Name: make, dtype: int64
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">top=df[<span class="string">&#x27;make&#x27;</span>].value_counts().head(<span class="number">5</span>)</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">prepare_X</span>(<span class="params">df</span>):</span><br><span class="line">    df = df.copy()</span><br><span class="line">    features = base.copy()</span><br><span class="line"></span><br><span class="line">    df[<span class="string">&#x27;age&#x27;</span>] = <span class="number">2017</span> - df.year</span><br><span class="line">    features.append(<span class="string">&#x27;age&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> v <span class="keyword">in</span> [<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]:</span><br><span class="line">        feature = <span class="string">&#x27;num_doors_%s&#x27;</span> % v</span><br><span class="line">        df[feature] = (df[<span class="string">&#x27;number_of_doors&#x27;</span>] == v).astype(<span class="built_in">int</span>)</span><br><span class="line">        features.append(feature)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> v <span class="keyword">in</span> [<span class="string">&#x27;chevrolet&#x27;</span>, <span class="string">&#x27;ford&#x27;</span>, <span class="string">&#x27;volkswagen&#x27;</span>, <span class="string">&#x27;toyota&#x27;</span>, <span class="string">&#x27;dodge&#x27;</span>]:</span><br><span class="line">        feature = <span class="string">&#x27;is_make_%s&#x27;</span> % v</span><br><span class="line">        df[feature] = (df[<span class="string">&#x27;make&#x27;</span>] == v).astype(<span class="built_in">int</span>)</span><br><span class="line">        features.append(feature)</span><br><span class="line">        </span><br><span class="line">    df_num = df[features]</span><br><span class="line">    df_num = df_num.fillna(<span class="number">0</span>)</span><br><span class="line">    X = df_num.values</span><br><span class="line">    <span class="keyword">return</span> X</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">X_train = prepare_X(df_train)</span><br><span class="line">w_0, w = train_linear_regression(X_train, y_train)</span><br><span class="line"></span><br><span class="line">y_pred = w_0 + X_train.dot(w)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;train:&#x27;</span>, rmse(y_train, y_pred))</span><br><span class="line"></span><br><span class="line">X_val = prepare_X(df_val)</span><br><span class="line">y_pred = w_0 + X_val.dot(w)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;validation:&#x27;</span>, rmse(y_val, y_pred))</span><br></pre></td></tr></table></figure>

<pre><code>train: 0.5058876515487503
validation: 0.5076038849555671
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">prepare_X</span>(<span class="params">df</span>):</span><br><span class="line">    df = df.copy()</span><br><span class="line">    features = base.copy()</span><br><span class="line"></span><br><span class="line">    df[<span class="string">&#x27;age&#x27;</span>] = <span class="number">2017</span> - df.year</span><br><span class="line">    features.append(<span class="string">&#x27;age&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> v <span class="keyword">in</span> [<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]:</span><br><span class="line">        feature = <span class="string">&#x27;num_doors_%s&#x27;</span> % v</span><br><span class="line">        df[feature] = (df[<span class="string">&#x27;number_of_doors&#x27;</span>] == v).astype(<span class="built_in">int</span>)</span><br><span class="line">        features.append(feature)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> v <span class="keyword">in</span> [<span class="string">&#x27;chevrolet&#x27;</span>, <span class="string">&#x27;ford&#x27;</span>, <span class="string">&#x27;volkswagen&#x27;</span>, <span class="string">&#x27;toyota&#x27;</span>, <span class="string">&#x27;dodge&#x27;</span>]:</span><br><span class="line">        feature = <span class="string">&#x27;is_make_%s&#x27;</span> % v</span><br><span class="line">        df[feature] = (df[<span class="string">&#x27;make&#x27;</span>] == v).astype(<span class="built_in">int</span>)</span><br><span class="line">        features.append(feature)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> v <span class="keyword">in</span> [<span class="string">&#x27;regular_unleaded&#x27;</span>, <span class="string">&#x27;premium_unleaded_(required)&#x27;</span>, </span><br><span class="line">              <span class="string">&#x27;premium_unleaded_(recommended)&#x27;</span>, <span class="string">&#x27;flex-fuel_(unleaded/e85)&#x27;</span>]:</span><br><span class="line">        feature = <span class="string">&#x27;is_type_%s&#x27;</span> % v</span><br><span class="line">        df[feature] = (df[<span class="string">&#x27;engine_fuel_type&#x27;</span>] == v).astype(<span class="built_in">int</span>)</span><br><span class="line">        features.append(feature)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> v <span class="keyword">in</span> [<span class="string">&#x27;automatic&#x27;</span>, <span class="string">&#x27;manual&#x27;</span>, <span class="string">&#x27;automated_manual&#x27;</span>]:</span><br><span class="line">        feature = <span class="string">&#x27;is_transmission_%s&#x27;</span> % v</span><br><span class="line">        df[feature] = (df[<span class="string">&#x27;transmission_type&#x27;</span>] == v).astype(<span class="built_in">int</span>)</span><br><span class="line">        features.append(feature)</span><br><span class="line">        </span><br><span class="line">    df_num = df[features]</span><br><span class="line">    df_num = df_num.fillna(<span class="number">0</span>)</span><br><span class="line">    X = df_num.values</span><br><span class="line">    <span class="keyword">return</span> X</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">X_train = prepare_X(df_train)</span><br><span class="line">w_0, w = train_linear_regression(X_train, y_train)</span><br><span class="line"></span><br><span class="line">y_pred = w_0 + X_train.dot(w)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;train:&#x27;</span>, rmse(y_train, y_pred))</span><br><span class="line"></span><br><span class="line">X_val = prepare_X(df_val)</span><br><span class="line">y_pred = w_0 + X_val.dot(w)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;validation:&#x27;</span>, rmse(y_val, y_pred))</span><br></pre></td></tr></table></figure>

<pre><code>train: 0.4745380510924003
validation: 0.46858791946591755
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">&#x27;driven_wheels&#x27;</span>].value_counts()</span><br></pre></td></tr></table></figure>




<pre><code>front_wheel_drive    4787
rear_wheel_drive     3371
all_wheel_drive      2353
four_wheel_drive     1403
Name: driven_wheels, dtype: int64
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">df[<span class="string">&#x27;market_category&#x27;</span>].value_counts().head(<span class="number">5</span>)</span><br></pre></td></tr></table></figure>




<pre><code>crossover             1110
flex_fuel              872
luxury                 855
luxury,performance     673
hatchback              641
Name: market_category, dtype: int64
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">&#x27;vehicle_size&#x27;</span>].value_counts().head(<span class="number">5</span>)</span><br></pre></td></tr></table></figure>




<pre><code>compact    4764
midsize    4373
large      2777
Name: vehicle_size, dtype: int64
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">&#x27;vehicle_size&#x27;</span>].value_counts().head(<span class="number">5</span>)</span><br></pre></td></tr></table></figure>




<pre><code>compact    4764
midsize    4373
large      2777
Name: vehicle_size, dtype: int64
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">prepare_X</span>(<span class="params">df</span>):</span><br><span class="line">    df = df.copy()</span><br><span class="line">    features = base.copy()</span><br><span class="line"></span><br><span class="line">    df[<span class="string">&#x27;age&#x27;</span>] = <span class="number">2017</span> - df.year</span><br><span class="line">    features.append(<span class="string">&#x27;age&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> v <span class="keyword">in</span> [<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]:</span><br><span class="line">        feature = <span class="string">&#x27;num_doors_%s&#x27;</span> % v</span><br><span class="line">        df[feature] = (df[<span class="string">&#x27;number_of_doors&#x27;</span>] == v).astype(<span class="built_in">int</span>)</span><br><span class="line">        features.append(feature)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> v <span class="keyword">in</span> [<span class="string">&#x27;chevrolet&#x27;</span>, <span class="string">&#x27;ford&#x27;</span>, <span class="string">&#x27;volkswagen&#x27;</span>, <span class="string">&#x27;toyota&#x27;</span>, <span class="string">&#x27;dodge&#x27;</span>]:</span><br><span class="line">        feature = <span class="string">&#x27;is_make_%s&#x27;</span> % v</span><br><span class="line">        df[feature] = (df[<span class="string">&#x27;make&#x27;</span>] == v).astype(<span class="built_in">int</span>)</span><br><span class="line">        features.append(feature)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> v <span class="keyword">in</span> [<span class="string">&#x27;regular_unleaded&#x27;</span>, <span class="string">&#x27;premium_unleaded_(required)&#x27;</span>, </span><br><span class="line">              <span class="string">&#x27;premium_unleaded_(recommended)&#x27;</span>, <span class="string">&#x27;flex-fuel_(unleaded/e85)&#x27;</span>]:</span><br><span class="line">        feature = <span class="string">&#x27;is_type_%s&#x27;</span> % v</span><br><span class="line">        df[feature] = (df[<span class="string">&#x27;engine_fuel_type&#x27;</span>] == v).astype(<span class="built_in">int</span>)</span><br><span class="line">        features.append(feature)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> v <span class="keyword">in</span> [<span class="string">&#x27;automatic&#x27;</span>, <span class="string">&#x27;manual&#x27;</span>, <span class="string">&#x27;automated_manual&#x27;</span>]:</span><br><span class="line">        feature = <span class="string">&#x27;is_transmission_%s&#x27;</span> % v</span><br><span class="line">        df[feature] = (df[<span class="string">&#x27;transmission_type&#x27;</span>] == v).astype(<span class="built_in">int</span>)</span><br><span class="line">        features.append(feature)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> v <span class="keyword">in</span> [<span class="string">&#x27;front_wheel_drive&#x27;</span>, <span class="string">&#x27;rear_wheel_drive&#x27;</span>, <span class="string">&#x27;all_wheel_drive&#x27;</span>, <span class="string">&#x27;four_wheel_drive&#x27;</span>]:</span><br><span class="line">        feature = <span class="string">&#x27;is_driven_wheens_%s&#x27;</span> % v</span><br><span class="line">        df[feature] = (df[<span class="string">&#x27;driven_wheels&#x27;</span>] == v).astype(<span class="built_in">int</span>)</span><br><span class="line">        features.append(feature)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> v <span class="keyword">in</span> [<span class="string">&#x27;crossover&#x27;</span>, <span class="string">&#x27;flex_fuel&#x27;</span>, <span class="string">&#x27;luxury&#x27;</span>, <span class="string">&#x27;luxury,performance&#x27;</span>, <span class="string">&#x27;hatchback&#x27;</span>]:</span><br><span class="line">        feature = <span class="string">&#x27;is_mc_%s&#x27;</span> % v</span><br><span class="line">        df[feature] = (df[<span class="string">&#x27;market_category&#x27;</span>] == v).astype(<span class="built_in">int</span>)</span><br><span class="line">        features.append(feature)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> v <span class="keyword">in</span> [<span class="string">&#x27;compact&#x27;</span>, <span class="string">&#x27;midsize&#x27;</span>, <span class="string">&#x27;large&#x27;</span>]:</span><br><span class="line">        feature = <span class="string">&#x27;is_size_%s&#x27;</span> % v</span><br><span class="line">        df[feature] = (df[<span class="string">&#x27;vehicle_size&#x27;</span>] == v).astype(<span class="built_in">int</span>)</span><br><span class="line">        features.append(feature)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> v <span class="keyword">in</span> [<span class="string">&#x27;sedan&#x27;</span>, <span class="string">&#x27;4dr_suv&#x27;</span>, <span class="string">&#x27;coupe&#x27;</span>, <span class="string">&#x27;convertible&#x27;</span>, <span class="string">&#x27;4dr_hatchback&#x27;</span>]:</span><br><span class="line">        feature = <span class="string">&#x27;is_style_%s&#x27;</span> % v</span><br><span class="line">        df[feature] = (df[<span class="string">&#x27;vehicle_style&#x27;</span>] == v).astype(<span class="built_in">int</span>)</span><br><span class="line">        features.append(feature)</span><br><span class="line">   </span><br><span class="line">    df_num = df[features]</span><br><span class="line">    df_num = df_num.fillna(<span class="number">0</span>)</span><br><span class="line">    X = df_num.values</span><br><span class="line">    <span class="keyword">return</span> X</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">X_train = prepare_X(df_train)</span><br><span class="line">w_0, w = train_linear_regression(X_train, y_train)</span><br><span class="line"></span><br><span class="line">y_pred = w_0 + X_train.dot(w)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;train:&#x27;</span>, rmse(y_train, y_pred))</span><br><span class="line"></span><br><span class="line">X_val = prepare_X(df_val)</span><br><span class="line">y_pred = w_0 + X_val.dot(w)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;validation:&#x27;</span>, rmse(y_val, y_pred))</span><br></pre></td></tr></table></figure>

<pre><code>train: 98.83799994732918
validation: 90.75198555498365
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">w_0</span><br></pre></td></tr></table></figure>




<pre><code>-1.1135946518113574e+16
</code></pre>
<p><strong>Regularization</strong> <a name="regularization"></a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train_linear_regression_reg</span>(<span class="params">X, y, r=<span class="number">0.0</span></span>):</span><br><span class="line">    ones = np.ones(X.shape[<span class="number">0</span>])</span><br><span class="line">    X = np.column_stack([ones, X])</span><br><span class="line"></span><br><span class="line">    XTX = X.T.dot(X)</span><br><span class="line">    reg = r * np.eye(XTX.shape[<span class="number">0</span>])</span><br><span class="line">    <span class="comment">#print(reg)</span></span><br><span class="line">    XTX = XTX + reg</span><br><span class="line"></span><br><span class="line">    XTX_inv = np.linalg.inv(XTX)</span><br><span class="line">    w = XTX_inv.dot(X.T).dot(y)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> w[<span class="number">0</span>], w[<span class="number">1</span>:]</span><br><span class="line">X_train = prepare_X(df_train)</span><br><span class="line"><span class="keyword">for</span> r <span class="keyword">in</span> [<span class="number">0</span>, <span class="number">0.001</span>, <span class="number">0.01</span>, <span class="number">0.1</span>, <span class="number">1</span>, <span class="number">10</span>]:</span><br><span class="line">    w_0, w = train_linear_regression_reg(X_train, y_train, r=r)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;%5s, %.2f, %.2f, %.2f&#x27;</span> % (r, w_0, w[<span class="number">13</span>], w[<span class="number">21</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>    0, -11135946518113574.00, 12.19, 11135946518113572.00
0.001, 7.20, -0.10, 1.81
 0.01, 7.18, -0.10, 1.81
  0.1, 7.05, -0.10, 1.78
    1, 6.22, -0.10, 1.56
   10, 4.39, -0.09, 1.08
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">X_train = prepare_X(df_train)</span><br><span class="line">w_0, w = train_linear_regression_reg(X_train, y_train, r=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">y_pred = w_0 + X_train.dot(w)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;train&#x27;</span>, rmse(y_train, y_pred))</span><br><span class="line"></span><br><span class="line">X_val = prepare_X(df_val)</span><br><span class="line">y_pred = w_0 + X_val.dot(w)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;val&#x27;</span>, rmse(y_val, y_pred))</span><br></pre></td></tr></table></figure>

<pre><code>train 98.83799994732918
val 90.75198555498365
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">X_train = prepare_X(df_train)</span><br><span class="line">X_val = prepare_X(df_val)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> r <span class="keyword">in</span> [<span class="number">0.000001</span>, <span class="number">0.0001</span>, <span class="number">0.001</span>, <span class="number">0.01</span>, <span class="number">0.1</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">10</span>]:</span><br><span class="line">    w_0, w = train_linear_regression_reg(X_train, y_train, r=r)</span><br><span class="line">    y_pred = w_0 + X_val.dot(w)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;%6s&#x27;</span> %r, rmse(y_val, y_pred))</span><br></pre></td></tr></table></figure>

<pre><code> 1e-06 0.46022485228775944
0.0001 0.4602254918041578
 0.001 0.4602267630259776
  0.01 0.460239496285643
   0.1 0.4603700695839839
     1 0.4618298042649753
     5 0.4684079627532594
    10 0.4757248100693656
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">X_train = prepare_X(df_train)</span><br><span class="line">w_0, w = train_linear_regression_reg(X_train, y_train, r=<span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line">X_val = prepare_X(df_val)</span><br><span class="line">y_pred = w_0 + X_val.dot(w)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;validation:&#x27;</span>, rmse(y_val, y_pred))</span><br><span class="line"></span><br><span class="line">X_test = prepare_X(df_test)</span><br><span class="line">y_pred = w_0 + X_test.dot(w)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;test:&#x27;</span>, rmse(y_test, y_pred))</span><br></pre></td></tr></table></figure>

<pre><code>validation: 0.460239496285643
test: 0.4571813679219644
</code></pre>
<p><strong>Using the model</strong> <a name="model"></a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">i = <span class="number">2</span></span><br><span class="line">ad = df_test.iloc[i].to_dict()</span><br><span class="line">ad</span><br></pre></td></tr></table></figure>




<pre><code>&#123;&#39;make&#39;: &#39;toyota&#39;,
 &#39;model&#39;: &#39;venza&#39;,
 &#39;year&#39;: 2013,
 &#39;engine_fuel_type&#39;: &#39;regular_unleaded&#39;,
 &#39;engine_hp&#39;: 268.0,
 &#39;engine_cylinders&#39;: 6.0,
 &#39;transmission_type&#39;: &#39;automatic&#39;,
 &#39;driven_wheels&#39;: &#39;all_wheel_drive&#39;,
 &#39;number_of_doors&#39;: 4.0,
 &#39;market_category&#39;: &#39;crossover,performance&#39;,
 &#39;vehicle_size&#39;: &#39;midsize&#39;,
 &#39;vehicle_style&#39;: &#39;wagon&#39;,
 &#39;highway_mpg&#39;: 25,
 &#39;city_mpg&#39;: 18,
 &#39;popularity&#39;: 2031&#125;
</code></pre>
<p>X_test &#x3D; prepare_X(pd.DataFrame([ad]))[0]
y_pred &#x3D; w_0 + X_test.dot(w)
suggestion &#x3D; np.expm1(y_pred) #this is to ensure greater precision than exp(x) - 1 for small values of x
suggestion</p>
</div><div class="article-licensing box"><div class="licensing-title"><p>Datatalks ML zoomcamp</p><p><a href="https://iphixli.github.io/Learning/datatalks-ml-zoomcamp/">https://iphixli.github.io/Learning/datatalks-ml-zoomcamp/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>Bera Iphigenie</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>2022-09-05</p></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/Machine-learning/">Machine learning</a><a class="link-muted mr-2" rel="tag" href="/tags/Datatalks/">Datatalks</a><a class="link-muted mr-2" rel="tag" href="/tags/study-notes/">study-notes</a></div><div class="sharethis-inline-share-buttons"></div><script src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-62f30acb0a28e668" defer></script></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/Projects/korean-drama-normalization/"><span class="level-item">Korean drama Normalization</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">Catalogue</h3><ul class="menu-list"><li><a class="level is-mobile" href="#Introduction"><span class="level-left"><span class="level-item">1</span><span class="level-item">Introduction</span></span></a></li><li><a class="level is-mobile" href="#Week-1-Introduction-to-Machine-Learning"><span class="level-left"><span class="level-item">2</span><span class="level-item">Week 1 - Introduction to Machine Learning</span></span></a></li><li><a class="level is-mobile" href="#Week-2-Regression"><span class="level-left"><span class="level-item">3</span><span class="level-item">Week 2 - Regression</span></span></a></li></ul></div></div><script src="/js/toc.js" defer></script></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/">BERA LOGS</a><p class="is-size-7"><span>&copy; 2023 Bera Iphigenie</span>Â Â Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>Â &amp;Â <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">Ã—</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>